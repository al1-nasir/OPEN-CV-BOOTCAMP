{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO V3 in open cv using cv2.dnn.readNetFrom()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:56:54.513442Z",
     "start_time": "2024-08-28T07:56:54.510362Z"
    }
   },
   "source": [
    "\n",
    "# # Download and unzip our images and YOLO files\n",
    "# !gdown --id 1rEV9xrrctxPwFPKvF3EC0sSNyYAZSEP4\n",
    "# !unzip -qq YOLO.zip"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:56:54.560803Z",
     "start_time": "2024-08-28T07:56:54.557626Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:56:54.731752Z",
     "start_time": "2024-08-28T07:56:54.611038Z"
    }
   },
   "source": [
    "labelsPath = \"YOLO/yolo/coco.names\"\n",
    "Label = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "COLORS = np.random.randint(0,255,size=(len(Label ) , 3) ,dtype= \"uint8\")\n",
    "\n",
    "weight_path = \"YOLO/yolo/yolov3.weights\"\n",
    "cfg_path = \"YOLO/yolo/yolov3.cfg\"\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(cfg_path , weight_path)\n",
    "\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "\n",
    "ln = net.getLayerNames()\n",
    "len(ln)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:56:54.812184Z",
     "start_time": "2024-08-28T07:56:54.809006Z"
    }
   },
   "source": [
    "my_path = \"YOLO/images/\"\n",
    "from ultralytics import YOLO\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:56:54.888509Z",
     "start_time": "2024-08-28T07:56:54.856687Z"
    }
   },
   "source": [
    "model = YOLO('yolov8n.pt')\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:57:01.701573Z",
     "start_time": "2024-08-28T07:56:54.910978Z"
    }
   },
   "source": [
    "results = model('YOLO/images/coffee_view.jpeg')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Couldn't load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.__version__ and your torchvision version with torchvision.__version__ and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYOLO/images/coffee_view.jpeg\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:173\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, source, stream, **kwargs)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    146\u001B[0m     source: Union[\u001B[38;5;28mstr\u001B[39m, Path, \u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m, np\u001B[38;5;241m.\u001B[39mndarray, torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    147\u001B[0m     stream: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    149\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n\u001B[1;32m    150\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001B[39;00m\n\u001B[1;32m    152\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(source, stream, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:563\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, source, stream, predictor, **kwargs)\u001B[0m\n\u001B[1;32m    561\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m prompts \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mset_prompts\u001B[39m\u001B[38;5;124m\"\u001B[39m):  \u001B[38;5;66;03m# for SAM-type models\u001B[39;00m\n\u001B[1;32m    562\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor\u001B[38;5;241m.\u001B[39mset_prompts(prompts)\n\u001B[0;32m--> 563\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor\u001B[38;5;241m.\u001B[39mpredict_cli(source\u001B[38;5;241m=\u001B[39msource) \u001B[38;5;28;01mif\u001B[39;00m is_cli \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor(source\u001B[38;5;241m=\u001B[39msource, stream\u001B[38;5;241m=\u001B[39mstream)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/predictor.py:168\u001B[0m, in \u001B[0;36mBasePredictor.__call__\u001B[0;34m(self, source, model, stream, *args, **kwargs)\u001B[0m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream_inference(source, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 168\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream_inference(source, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:35\u001B[0m, in \u001B[0;36m_wrap_generator.<locals>.generator_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;66;03m# Issuing `None` to a generator fires it up\u001B[39;00m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m---> 35\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m             \u001B[38;5;66;03m# Forward the response to our caller and get its next request\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/predictor.py:261\u001B[0m, in \u001B[0;36mBasePredictor.stream_inference\u001B[0;34m(self, source, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;66;03m# Postprocess\u001B[39;00m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m profilers[\u001B[38;5;241m2\u001B[39m]:\n\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(preds, im, im0s)\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_callbacks(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_predict_postprocess_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# Visualize, save, write results\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/models/yolo/detect/predict.py:25\u001B[0m, in \u001B[0;36mDetectionPredictor.postprocess\u001B[0;34m(self, preds, img, orig_imgs)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpostprocess\u001B[39m(\u001B[38;5;28mself\u001B[39m, preds, img, orig_imgs):\n\u001B[1;32m     24\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Post-processes predictions and returns a list of Results objects.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m     preds \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mnon_max_suppression(\n\u001B[1;32m     26\u001B[0m         preds,\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mconf,\n\u001B[1;32m     28\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39miou,\n\u001B[1;32m     29\u001B[0m         agnostic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39magnostic_nms,\n\u001B[1;32m     30\u001B[0m         max_det\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mmax_det,\n\u001B[1;32m     31\u001B[0m         classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mclasses,\n\u001B[1;32m     32\u001B[0m     )\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(orig_imgs, \u001B[38;5;28mlist\u001B[39m):  \u001B[38;5;66;03m# input images are a torch.Tensor, not a list\u001B[39;00m\n\u001B[1;32m     35\u001B[0m         orig_imgs \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mconvert_torch2numpy_batch(orig_imgs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/utils/ops.py:291\u001B[0m, in \u001B[0;36mnon_max_suppression\u001B[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated)\u001B[0m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    290\u001B[0m     boxes \u001B[38;5;241m=\u001B[39m x[:, :\u001B[38;5;241m4\u001B[39m] \u001B[38;5;241m+\u001B[39m c  \u001B[38;5;66;03m# boxes (offset by class)\u001B[39;00m\n\u001B[0;32m--> 291\u001B[0m     i \u001B[38;5;241m=\u001B[39m torchvision\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mnms(boxes, scores, iou_thres)  \u001B[38;5;66;03m# NMS\u001B[39;00m\n\u001B[1;32m    292\u001B[0m i \u001B[38;5;241m=\u001B[39m i[:max_det]  \u001B[38;5;66;03m# limit detections\u001B[39;00m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;66;03m# # Experimental\u001B[39;00m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;66;03m# merge = False  # use merge-NMS\u001B[39;00m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;66;03m# if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;66;03m#     if redundant:\u001B[39;00m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;66;03m#         i = i[iou.sum(1) > 1]  # require redundancy\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/ops/boxes.py:40\u001B[0m, in \u001B[0;36mnms\u001B[0;34m(boxes, scores, iou_threshold)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_tracing():\n\u001B[1;32m     39\u001B[0m     _log_api_usage_once(nms)\n\u001B[0;32m---> 40\u001B[0m _assert_has_ops()\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mtorchvision\u001B[38;5;241m.\u001B[39mnms(boxes, scores, iou_threshold)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/extension.py:48\u001B[0m, in \u001B[0;36m_assert_has_ops\u001B[0;34m()\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_assert_has_ops\u001B[39m():\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _has_ops():\n\u001B[0;32m---> 48\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m     49\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt load custom C++ ops. This can happen if your PyTorch and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     50\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorchvision versions are incompatible, or if you had errors while compiling \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     51\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorchvision from source. For further information on the compatible versions, check \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     52\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://github.com/pytorch/vision#installation for the compatibility matrix. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     53\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease check your PyTorch version with torch.__version__ and your torchvision \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     54\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mversion with torchvision.__version__ and verify if they are compatible, and if not \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     55\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease reinstall torchvision so that it matches your PyTorch install.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     56\u001B[0m         )\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Couldn't load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.__version__ and your torchvision version with torchvision.__version__ and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install."
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T07:57:01.776437724Z",
     "start_time": "2024-08-28T07:39:50.733371Z"
    }
   },
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained YOLOv8 model (here using YOLOv8n - the nano model)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Specify the path to the input image\n",
    "image_path = '/home/al1_nasir/Desktop/OPEN_CV BOOTCAMP/YOLO_in_opencv/YOLO/images/coffee_view.jpeg'\n",
    "\n",
    "# Perform inference on the image\n",
    "results = model(image_path)\n",
    "\n",
    "# Access the boxes, class names, and original image\n",
    "boxes = results[0].boxes  # Detected boxes\n",
    "names = results[0].names  # Class names\n",
    "\n",
    "# Load the original image\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# Convert the image to OpenCV format for drawing boxes\n",
    "img_cv2 = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Draw each detected box on the image\n",
    "for box in boxes:\n",
    "    # Get the bounding box coordinates\n",
    "    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "    # Get the class ID and confidence\n",
    "    class_id = int(box.cls[0])\n",
    "    confidence = box.conf[0]\n",
    "    # Get the label name\n",
    "    label = names[class_id]\n",
    "    # Create the label text\n",
    "    label_text = f'{label} ({confidence:.2f})'\n",
    "    # Draw the bounding box\n",
    "    cv2.rectangle(img_cv2, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    # Draw the label above the box\n",
    "    cv2.putText(img_cv2, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Save the image with bounding boxes\n",
    "output_path = 'runs/detect/predict/coffee_view_detected.jpeg'\n",
    "cv2.imwrite(output_path, img_cv2)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Couldn't load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.__version__ and your torchvision version with torchvision.__version__ and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m image_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/home/al1_nasir/Desktop/OPEN_CV BOOTCAMP/YOLO_in_opencv/YOLO/images/coffee_view.jpeg\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Perform inference on the image\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m results \u001B[38;5;241m=\u001B[39m model(image_path)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Access the boxes, class names, and original image\u001B[39;00m\n\u001B[1;32m     16\u001B[0m boxes \u001B[38;5;241m=\u001B[39m results[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mboxes  \u001B[38;5;66;03m# Detected boxes\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:173\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, source, stream, **kwargs)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    146\u001B[0m     source: Union[\u001B[38;5;28mstr\u001B[39m, Path, \u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m, np\u001B[38;5;241m.\u001B[39mndarray, torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    147\u001B[0m     stream: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    149\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m:\n\u001B[1;32m    150\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001B[39;00m\n\u001B[1;32m    152\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(source, stream, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:563\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, source, stream, predictor, **kwargs)\u001B[0m\n\u001B[1;32m    561\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m prompts \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mset_prompts\u001B[39m\u001B[38;5;124m\"\u001B[39m):  \u001B[38;5;66;03m# for SAM-type models\u001B[39;00m\n\u001B[1;32m    562\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor\u001B[38;5;241m.\u001B[39mset_prompts(prompts)\n\u001B[0;32m--> 563\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor\u001B[38;5;241m.\u001B[39mpredict_cli(source\u001B[38;5;241m=\u001B[39msource) \u001B[38;5;28;01mif\u001B[39;00m is_cli \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor(source\u001B[38;5;241m=\u001B[39msource, stream\u001B[38;5;241m=\u001B[39mstream)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/predictor.py:168\u001B[0m, in \u001B[0;36mBasePredictor.__call__\u001B[0;34m(self, source, model, stream, *args, **kwargs)\u001B[0m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream_inference(source, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 168\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream_inference(source, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:35\u001B[0m, in \u001B[0;36m_wrap_generator.<locals>.generator_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;66;03m# Issuing `None` to a generator fires it up\u001B[39;00m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m---> 35\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m             \u001B[38;5;66;03m# Forward the response to our caller and get its next request\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/predictor.py:261\u001B[0m, in \u001B[0;36mBasePredictor.stream_inference\u001B[0;34m(self, source, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;66;03m# Postprocess\u001B[39;00m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m profilers[\u001B[38;5;241m2\u001B[39m]:\n\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(preds, im, im0s)\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_callbacks(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon_predict_postprocess_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# Visualize, save, write results\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/models/yolo/detect/predict.py:25\u001B[0m, in \u001B[0;36mDetectionPredictor.postprocess\u001B[0;34m(self, preds, img, orig_imgs)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpostprocess\u001B[39m(\u001B[38;5;28mself\u001B[39m, preds, img, orig_imgs):\n\u001B[1;32m     24\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Post-processes predictions and returns a list of Results objects.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m     preds \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mnon_max_suppression(\n\u001B[1;32m     26\u001B[0m         preds,\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mconf,\n\u001B[1;32m     28\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39miou,\n\u001B[1;32m     29\u001B[0m         agnostic\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39magnostic_nms,\n\u001B[1;32m     30\u001B[0m         max_det\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mmax_det,\n\u001B[1;32m     31\u001B[0m         classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mclasses,\n\u001B[1;32m     32\u001B[0m     )\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(orig_imgs, \u001B[38;5;28mlist\u001B[39m):  \u001B[38;5;66;03m# input images are a torch.Tensor, not a list\u001B[39;00m\n\u001B[1;32m     35\u001B[0m         orig_imgs \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mconvert_torch2numpy_batch(orig_imgs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/utils/ops.py:291\u001B[0m, in \u001B[0;36mnon_max_suppression\u001B[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated)\u001B[0m\n\u001B[1;32m    289\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    290\u001B[0m     boxes \u001B[38;5;241m=\u001B[39m x[:, :\u001B[38;5;241m4\u001B[39m] \u001B[38;5;241m+\u001B[39m c  \u001B[38;5;66;03m# boxes (offset by class)\u001B[39;00m\n\u001B[0;32m--> 291\u001B[0m     i \u001B[38;5;241m=\u001B[39m torchvision\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mnms(boxes, scores, iou_thres)  \u001B[38;5;66;03m# NMS\u001B[39;00m\n\u001B[1;32m    292\u001B[0m i \u001B[38;5;241m=\u001B[39m i[:max_det]  \u001B[38;5;66;03m# limit detections\u001B[39;00m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;66;03m# # Experimental\u001B[39;00m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;66;03m# merge = False  # use merge-NMS\u001B[39;00m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;66;03m# if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;66;03m#     if redundant:\u001B[39;00m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;66;03m#         i = i[iou.sum(1) > 1]  # require redundancy\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/ops/boxes.py:40\u001B[0m, in \u001B[0;36mnms\u001B[0;34m(boxes, scores, iou_threshold)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_tracing():\n\u001B[1;32m     39\u001B[0m     _log_api_usage_once(nms)\n\u001B[0;32m---> 40\u001B[0m _assert_has_ops()\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mtorchvision\u001B[38;5;241m.\u001B[39mnms(boxes, scores, iou_threshold)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/extension.py:48\u001B[0m, in \u001B[0;36m_assert_has_ops\u001B[0;34m()\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_assert_has_ops\u001B[39m():\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _has_ops():\n\u001B[0;32m---> 48\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m     49\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt load custom C++ ops. This can happen if your PyTorch and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     50\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorchvision versions are incompatible, or if you had errors while compiling \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     51\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorchvision from source. For further information on the compatible versions, check \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     52\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://github.com/pytorch/vision#installation for the compatibility matrix. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     53\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease check your PyTorch version with torch.__version__ and your torchvision \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     54\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mversion with torchvision.__version__ and verify if they are compatible, and if not \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     55\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease reinstall torchvision so that it matches your PyTorch install.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     56\u001B[0m         )\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Couldn't load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.__version__ and your torchvision version with torchvision.__version__ and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install."
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
